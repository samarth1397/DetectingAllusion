{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loading true allusion metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_off = open(\"../output/nietzsche/orderedTuples.pickle\",\"rb\")\n",
    "scoreTuples = pickle.load(pickle_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scoreTuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scoreTuples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6438726881801184,\n",
       " 0.9006290435791016,\n",
       " 0.8976383209228516,\n",
       " 0.7947423458099365,\n",
       " 0.8483303189277649,\n",
       " 0.770755504551485,\n",
       " 4,\n",
       " 'gott weise menschen bestehen ',\n",
       " 0.644375346333208,\n",
       " 0,\n",
       " 0.125,\n",
       " 0.16666666666666666,\n",
       " 0.09090909090909091)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoreTuples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueAllusions=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tup in scoreTuples:\n",
    "    trueAllusions.append(list(tup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trueAllusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loading non allusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_off = open(\"../output/n1-lim//orderedTuples.pickle\",\"rb\")\n",
    "scoreTuples_1 = pickle.load(pickle_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scoreTuples_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_off = open(\"../output/n3-lim//orderedTuples.pickle\",\"rb\")\n",
    "scoreTuples_2 = pickle.load(pickle_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scoreTuples_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "falseAllusions=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tup in scoreTuples_1:\n",
    "    falseAllusions.append(list(tup)[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tup in scoreTuples_2:\n",
    "    falseAllusions.append(list(tup)[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(falseAllusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Converting to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr=np.array(trueAllusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa=np.array(falseAllusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 13)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* deleting LCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr=np.delete(tr,7,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 12)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa=np.delete(fa,7,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 12)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.7656562163496606', '0.8395000696182251', '0.8226218819618225',\n",
       "       '0.5775456428527832', '0.6651535034179688', '0.7941390491557416',\n",
       "       '1', '0.7799910540677606', '1', '0.08695652173913043',\n",
       "       '0.09090909090909091', '0.0'], dtype='<U32')"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr=tr.astype(float)\n",
    "tr=np.nan_to_num(tr)\n",
    "fa=fa.astype(float)\n",
    "fa=np.nan_to_num(fa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Basic exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.append(list(np.amin(tr,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.append(list(np.amax(tr,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.append(list(np.mean(tr,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.append(list(np.median(tr,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.append(list(np.amin(fa,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.append(list(np.amax(fa,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.append(list(np.mean(fa,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.append(list(np.median(fa,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "colNames=['syntactic similarity', 'semantic similarity all words', 'semantic similarity without stopwords', \n",
    "          'semantic similarity nouns', 'semantic similarity verbs', 'average similairty',\n",
    "          'lcs length', 'syntactic similarity without tokens', 'common proper nouns', 'jaccard nouns', \n",
    "          'jaccard verbs', 'jaccard adjectives']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 12)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=colNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>syntactic similarity</th>\n",
       "      <th>semantic similarity all words</th>\n",
       "      <th>semantic similarity without stopwords</th>\n",
       "      <th>semantic similarity nouns</th>\n",
       "      <th>semantic similarity verbs</th>\n",
       "      <th>average similairty</th>\n",
       "      <th>lcs length</th>\n",
       "      <th>syntactic similarity without tokens</th>\n",
       "      <th>common proper nouns</th>\n",
       "      <th>jaccard nouns</th>\n",
       "      <th>jaccard verbs</th>\n",
       "      <th>jaccard adjectives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.448897</td>\n",
       "      <td>0.704882</td>\n",
       "      <td>0.704882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.469748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.935435</td>\n",
       "      <td>0.986720</td>\n",
       "      <td>0.985347</td>\n",
       "      <td>0.949121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.911247</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.957476</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.744608</td>\n",
       "      <td>0.877355</td>\n",
       "      <td>0.873170</td>\n",
       "      <td>0.635241</td>\n",
       "      <td>0.707406</td>\n",
       "      <td>0.808889</td>\n",
       "      <td>8.041667</td>\n",
       "      <td>0.801359</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.204844</td>\n",
       "      <td>0.201905</td>\n",
       "      <td>0.164902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.752295</td>\n",
       "      <td>0.905122</td>\n",
       "      <td>0.899967</td>\n",
       "      <td>0.796020</td>\n",
       "      <td>0.766386</td>\n",
       "      <td>0.836791</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.864553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>0.118056</td>\n",
       "      <td>0.108187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.656616</td>\n",
       "      <td>0.756983</td>\n",
       "      <td>0.752281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.647783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.833664</td>\n",
       "      <td>0.948004</td>\n",
       "      <td>0.945332</td>\n",
       "      <td>0.957479</td>\n",
       "      <td>0.883739</td>\n",
       "      <td>0.810265</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.896559</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.728172</td>\n",
       "      <td>0.878747</td>\n",
       "      <td>0.873100</td>\n",
       "      <td>0.615945</td>\n",
       "      <td>0.722802</td>\n",
       "      <td>0.800636</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.797798</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.014510</td>\n",
       "      <td>0.014677</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.730053</td>\n",
       "      <td>0.882680</td>\n",
       "      <td>0.875126</td>\n",
       "      <td>0.648156</td>\n",
       "      <td>0.747126</td>\n",
       "      <td>0.801146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.809060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   syntactic similarity  semantic similarity all words  \\\n",
       "0              0.448897                       0.704882   \n",
       "1              0.935435                       0.986720   \n",
       "2              0.744608                       0.877355   \n",
       "3              0.752295                       0.905122   \n",
       "4              0.656616                       0.756983   \n",
       "5              0.833664                       0.948004   \n",
       "6              0.728172                       0.878747   \n",
       "7              0.730053                       0.882680   \n",
       "\n",
       "   semantic similarity without stopwords  semantic similarity nouns  \\\n",
       "0                               0.704882                   0.000000   \n",
       "1                               0.985347                   0.949121   \n",
       "2                               0.873170                   0.635241   \n",
       "3                               0.899967                   0.796020   \n",
       "4                               0.752281                   0.000000   \n",
       "5                               0.945332                   0.957479   \n",
       "6                               0.873100                   0.615945   \n",
       "7                               0.875126                   0.648156   \n",
       "\n",
       "   semantic similarity verbs  average similairty  lcs length  \\\n",
       "0                   0.000000            0.610141    0.000000   \n",
       "1                   1.000000            0.911247   43.000000   \n",
       "2                   0.707406            0.808889    8.041667   \n",
       "3                   0.766386            0.836791    6.500000   \n",
       "4                   0.000000            0.790105    0.000000   \n",
       "5                   0.883739            0.810265    3.000000   \n",
       "6                   0.722802            0.800636    0.600000   \n",
       "7                   0.747126            0.801146    0.000000   \n",
       "\n",
       "   syntactic similarity without tokens  common proper nouns  jaccard nouns  \\\n",
       "0                             0.469748             0.000000       0.000000   \n",
       "1                             0.957476             3.000000       0.555556   \n",
       "2                             0.801359             0.416667       0.204844   \n",
       "3                             0.864553             0.000000       0.158333   \n",
       "4                             0.647783             0.000000       0.000000   \n",
       "5                             0.896559             2.000000       0.166667   \n",
       "6                             0.797798             0.160000       0.014510   \n",
       "7                             0.809060             0.000000       0.000000   \n",
       "\n",
       "   jaccard verbs  jaccard adjectives  \n",
       "0       0.000000            0.000000  \n",
       "1       1.000000            1.000000  \n",
       "2       0.201905            0.164902  \n",
       "3       0.118056            0.108187  \n",
       "4       0.000000            0.000000  \n",
       "5       0.130435            0.000000  \n",
       "6       0.014677            0.000000  \n",
       "7       0.000000            0.000000  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x=np.ones((tr.shape[0],tr.shape[1]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x[:,:-1]=tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_x=np.zeros((fa.shape[0],fa.shape[1]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_x[:,:-1]=fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.concatenate((tr_x,fa_x),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 13)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=X[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 12)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0.])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python personal",
   "language": "python",
   "name": "py3env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
