{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from nltk.corpus import wordnet as wn\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import re\n",
    "import bisect\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "import os\n",
    "from gutenberg.cleanup import strip_headers\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('/home/users2/mehrotsh/scripts/packages/stanford-corenlp-full-2018-02-27')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree(): \n",
    "    return defaultdict(tree)\n",
    "\n",
    "\n",
    "def _leadingSpaces_(target):\n",
    "    return len(target) - len(target.lstrip())\n",
    "\n",
    "def _findParent_(curIndent, parid, treeRef):\n",
    "    tmpid = parid\n",
    "    while (curIndent <= treeRef[tmpid]['indent']):\n",
    "        tmpid = treeRef[tmpid]['parid']\n",
    "    return tmpid\n",
    "\n",
    "\n",
    "def generateTree(rawTokens, treeRef):\n",
    "\n",
    "    # (token\n",
    "    REGEX_OPEN = r\"^\\s*\\(([a-zA-Z0-9_']*)\\s*$\"\n",
    "    # (token (tok1 tok2) (tok3 tok4) .... (tokx toky))\n",
    "    REGEX_COMP = r\"^\\s*\\(([a-zA-Z0-9_']+)\\s*((?:[(]([a-zA-Z0-9_;.,?'!]+)\\s*([a-zA-Z0-9_;\\.,?!']+)[)]\\s*)+)\"    \n",
    "    # (, ,) as stand-alone. Used for match() not search()\n",
    "    REGEX_PUNC = r\"^\\s*\\([,!?.'\\\"]\\s*[,!?.'\\\"]\\)\"\n",
    "    # (tok1 tok2) as stand-alone\n",
    "    REGEX_SOLO_PAIR = r\"^\\s*\\(([a-zA-Z0-9_']+)\\s*([a-zA-Z0-9_']+)\\)\"\n",
    "    # (tok1 tok2) used in search()\n",
    "    REGEX_ISOL_IN_COMP = r\"\\(([a-zA-Z0-9_;.,?!']+)\\s*([a-zA-Z0-9_;.,?!']+)\\)\"\n",
    "    # (punc punc) used in search()\n",
    "    REGEX_PUNC_SOLO = r\"\\([,!?.'\\\"]\\s*[,!?.'\\\"]\\)\"\n",
    "  \n",
    "    # manually insert Root token \n",
    "    treeRef[len(treeRef)] = {'curid':0, \n",
    "                             'parid':-1, \n",
    "                             'posOrTok':'ROOT', \n",
    "                             'indent':0,\n",
    "                            'children':[],\n",
    "                            'childrenTok':[]}\n",
    "    ID_CTR = 1\n",
    "    \n",
    "    for tok in rawTokens[1:]:\n",
    "        \n",
    "        curIndent = _leadingSpaces_(tok) # the current indent level\n",
    "        parid = _findParent_(curIndent, ID_CTR-1, treeRef) # determine parid\n",
    "        \n",
    "        # CHECK FOR COMPOSITE TOKENS\n",
    "        checkChild = re.match(REGEX_COMP, tok)\n",
    "        if (checkChild):\n",
    "            treeRef[ID_CTR] = {'curid':ID_CTR, \n",
    "                               'parid':parid, \n",
    "                               'posOrTok':checkChild.group(1), \n",
    "                               'indent':curIndent,\n",
    "                              'children':[],\n",
    "                              'childrenTok':[]}\n",
    "            upCTR = ID_CTR\n",
    "            ID_CTR += 1\n",
    "            \n",
    "            subCheck = re.sub(REGEX_PUNC_SOLO,'',checkChild.group(2))\n",
    "            subs = re.findall(REGEX_ISOL_IN_COMP, subCheck) \n",
    "            for ch in subs:\n",
    "                treeRef[ID_CTR] = {'curid':ID_CTR, \n",
    "                                   'parid':upCTR, \n",
    "                                   'posOrTok':ch[0], \n",
    "                                   'indent':curIndent+2,\n",
    "                                  'children':[],\n",
    "                                  'childrenTok':[]}\n",
    "                ID_CTR += 1\n",
    "                treeRef[ID_CTR] = {'curid':ID_CTR, \n",
    "                                   'parid':ID_CTR-1, \n",
    "                                   'posOrTok':ch[1], \n",
    "                                   'indent':curIndent+2,\n",
    "                                  'children':[],\n",
    "                                  'childrenTok':[]}\n",
    "                ID_CTR += 1\n",
    "            continue\n",
    "           \n",
    "\n",
    "            \n",
    "        checkSingle = re.match(REGEX_SOLO_PAIR, tok)\n",
    "        if (checkSingle):\n",
    "            treeRef[ID_CTR] = {'curid':ID_CTR, \n",
    "                               'parid':parid, \n",
    "                               'posOrTok':checkSingle.group(1), \n",
    "                               'indent':curIndent+2,\n",
    "                              'children':[],\n",
    "                              'childrenTok':[]}\n",
    "            ID_CTR += 1\n",
    "            treeRef[ID_CTR] = {'curid':ID_CTR, \n",
    "                               'parid':ID_CTR-1, \n",
    "                               'posOrTok':checkSingle.group(2), \n",
    "                               'indent':curIndent+2,\n",
    "                              'children':[],\n",
    "                              'childrenTok':[]}\n",
    "            ID_CTR += 1\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        checkPunc = re.match(REGEX_PUNC, tok)\n",
    "        if (checkPunc): # ignore punctuation\n",
    "            continue\n",
    "\n",
    "        checkMatch = re.match(REGEX_OPEN, tok)\n",
    "        if (checkMatch):\n",
    "            treeRef[ID_CTR] = {'curid':ID_CTR, \n",
    "                               'parid':parid, \n",
    "                               'posOrTok':checkMatch.group(1), \n",
    "                               'indent':curIndent,\n",
    "                              'children':[],\n",
    "                              'childrenTok':[]}\n",
    "            ID_CTR += 1\n",
    "            continue\n",
    "\n",
    "    return\n",
    "            \n",
    "\n",
    "def flipTree(treeRef):\n",
    "    # Pass 1 fill in children\n",
    "    for k,v in treeRef.items():\n",
    "        if (k > 0):\n",
    "            bisect.insort(treeRef[v['parid']]['children'], k)\n",
    "    # Pass 2 map children to tokens\n",
    "    for k,v in treeRef.items():\n",
    "        if (k > 0):\n",
    "            treeRef[k]['childrenTok'] = [treeRef[ch]['posOrTok'] for ch in treeRef[k]['children']]\n",
    "    treeRef[0]['childrenTok'] = treeRef[1]['posOrTok']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _isLeaf_(tree, parentNode):\n",
    "    return (len(tree[parentNode]['children']) == 0)\n",
    "\n",
    "def _isPreterminal_(tree, parentNode):\n",
    "    for idx in tree[parentNode]['children']:\n",
    "        if not _isLeaf_(tree, idx):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "'''\n",
    "Implementation of the Colins-Duffy or Subset-Tree (SST) Kernel\n",
    "'''\n",
    "\n",
    "def _cdHelper_(tree1, tree2, node1, node2, store, lam, SST_ON):\n",
    "    # No duplicate computations\n",
    "    if store[node1, node2] >= 0:\n",
    "        return\n",
    "\n",
    "    # Leaves yield similarity score by definition\n",
    "    if (_isLeaf_(tree1, node1) or _isLeaf_(tree2, node2)):\n",
    "        store[node1, node2] = 0\n",
    "        return\n",
    "\n",
    "    # same parent node\n",
    "    if tree1[node1]['posOrTok'] == tree2[node2]['posOrTok']:\n",
    "        # same children tokens\n",
    "        if tree1[node1]['childrenTok'] == tree2[node2]['childrenTok']:\n",
    "            # Check if both nodes are pre-terminal\n",
    "            if _isPreterminal_(tree1, node1) and _isPreterminal_(tree2, node2):\n",
    "                store[node1, node2] = lam\n",
    "                return\n",
    "            # Not pre-terminal. Recurse among the children of both token trees.\n",
    "            else:\n",
    "                nChildren = len(tree1[node1]['children'])\n",
    "\n",
    "                runningTotal = None\n",
    "                for idx in range(nChildren):\n",
    "                     # index ->  node_id\n",
    "                    tmp_n1 = tree1[node1]['children'][idx]\n",
    "                    tmp_n2 = tree2[node2]['children'][idx]\n",
    "                    # Recursively run helper\n",
    "                    _cdHelper_(tree1, tree2, tmp_n1, tmp_n2, store, lam, SST_ON)\n",
    "                    # Set the initial value for the layer. Else multiplicative product.\n",
    "                    if (runningTotal == None):\n",
    "                        runningTotal = SST_ON + store[tmp_n1, tmp_n2]\n",
    "                    else:\n",
    "                        runningTotal *= (SST_ON + store[tmp_n1, tmp_n2])\n",
    "\n",
    "                store[node1, node2] = lam * runningTotal\n",
    "                return\n",
    "        else:\n",
    "            store[node1, node2] = 0\n",
    "    else: # parent nodes are different\n",
    "        store[node1, node2] = 0\n",
    "        return\n",
    "\n",
    "\n",
    "def _cdKernel_(tree1, tree2, lam, SST_ON):\n",
    "    # Fill the initial state of the store\n",
    "    store = np.empty((len(tree1), len(tree2)))\n",
    "    store.fill(-1)\n",
    "    # O(N^2) to compute the tree dot product\n",
    "    for i in range(len(tree1)):\n",
    "        for j in range(len(tree2)):\n",
    "            _cdHelper_(tree1, tree2, i, j, store, lam, SST_ON)\n",
    "\n",
    "    return store.sum()\n",
    "\n",
    "'''\n",
    "Returns a tuple w/ format: (raw, normalized)\n",
    "If NORMALIZE_FLAG set to False, tuple[1] = -1\n",
    "'''\n",
    "def CollinsDuffy(tree1, tree2, lam, NORMALIZE_FLAG, SST_ON):\n",
    "    raw_score = _cdKernel_(tree1, tree2, lam, SST_ON)\n",
    "    if (NORMALIZE_FLAG):\n",
    "        t1_score = _cdKernel_(tree1, tree1, lam, SST_ON)\n",
    "        t2_score = _cdKernel_(tree2, tree2, lam, SST_ON)\n",
    "        return (raw_score,(raw_score / math.sqrt(t1_score * t2_score)))\n",
    "    else:\n",
    "        return (raw_score,-1)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Implementation of the Partial Tree (PT) Kernel from:\n",
    "\"Efficient Convolution Kernels for Dependency and Constituent Syntactic Trees\"\n",
    "by Alessandro Moschitti\n",
    "'''\n",
    "\n",
    "'''\n",
    "The delta function is stolen from the Collins-Duffy kernel\n",
    "'''\n",
    "\n",
    "def _deltaP_(tree1, tree2, seq1, seq2, store, lam, mu, p):\n",
    "\n",
    "#     # Enumerate subsequences of length p+1 for each child set\n",
    "    if p == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        # generate delta(a,b)\n",
    "        _delta_(tree1, tree2, seq1[-1], seq2[-1], store, lam, mu)\n",
    "        if store[seq1[-1], seq2[-1]] == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            runningTot = 0\n",
    "            for i in range(p-1, len(seq1)-1):\n",
    "                for r in range(p-1, len(seq2)-1):\n",
    "                    scaleFactor = pow(lam, len(seq1[:-1])-i+len(seq2[:-1])-r)\n",
    "                    dp = _deltaP_(tree1, tree2, seq1[:i], seq2[:r], store, lam, mu, p-1)\n",
    "                    runningTot += (scaleFactor * dp)\n",
    "            return runningTot\n",
    "\n",
    "def _delta_(tree1, tree2, node1, node2, store, lam, mu):\n",
    "\n",
    "    # No duplicate computations\n",
    "    if store[node1, node2] >= 0:\n",
    "        return\n",
    "\n",
    "    # Leaves yield similarity score by definition\n",
    "    if (_isLeaf_(tree1, node1) or _isLeaf_(tree2, node2)):\n",
    "        store[node1, node2] = 0\n",
    "        return\n",
    "\n",
    "    # same parent node\n",
    "    if tree1[node1]['posOrTok'] == tree2[node2]['posOrTok']:\n",
    "\n",
    "        if _isPreterminal_(tree1, node1) and _isPreterminal_(tree2, node2):\n",
    "            if tree1[node1]['childrenTok'] == tree2[node2]['childrenTok']:\n",
    "                store[node1, node2] = lam\n",
    "            else:\n",
    "                store[node1, node2] = 0\n",
    "            return\n",
    "\n",
    "        else:\n",
    "            # establishes p_max\n",
    "            childmin = min(len(tree1[node1]['children']), len(tree2[node2]['children']))\n",
    "            deltaTot = 0\n",
    "            for p in range(1,childmin+1):\n",
    "                # compute delta_p\n",
    "                deltaTot += _deltaP_(tree1, tree2,\n",
    "                                     tree1[node1]['children'],\n",
    "                                     tree2[node2]['children'], store, lam, mu, p)\n",
    "\n",
    "            store[node1, node2] = mu * (pow(lam,2) + deltaTot)\n",
    "            return\n",
    "\n",
    "    else:\n",
    "        # parent nodes are different\n",
    "        store[node1, node2] = 0\n",
    "        return\n",
    "\n",
    "def _ptKernel_(tree1, tree2, lam, mu):\n",
    "    # Fill the initial state of the store\n",
    "    store = np.empty((len(tree1), len(tree2)))\n",
    "    store.fill(-1)\n",
    "\n",
    "    # O(N^2) to compute the tree dot product\n",
    "    for i in range(len(tree1)):\n",
    "        for j in range(len(tree2)):\n",
    "            _delta_(tree1, tree2, i, j, store, lam, mu)\n",
    "\n",
    "    return store.sum()\n",
    "\n",
    "'''\n",
    "Returns a tuple w/ format: (raw, normalized)\n",
    "If NORMALIZE_FLAG set to False, tuple[1] = -1\n",
    "'''\n",
    "def MoschittiPT(tree1, tree2, lam, mu, NORMALIZE_FLAG):\n",
    "    raw_score = _ptKernel_(tree1, tree2, lam, mu)\n",
    "    if (NORMALIZE_FLAG):\n",
    "        t1_score = _ptKernel_(tree1, tree1, lam, mu)\n",
    "        t2_score = _ptKernel_(tree2, tree2, lam, mu)\n",
    "        return (raw_score,(raw_score / math.sqrt(t1_score * t2_score)))\n",
    "    else:\n",
    "        return (raw_score,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on example sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent1='the quick brown fox jumps over the lazy dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent2='the slow fox jumped over the quick dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent5='the fast dark cat jumped over the slow mouse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent3='usually, a fox jumps over a dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent4='cats sleep throughout the day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNLPToks(rawSentence):\n",
    "    output = nlp.annotate(rawSentence, properties={'annotators': 'tokenize,ssplit,pos,parse','outputFormat': 'json'})\n",
    "    output=ast.literal_eval(output)\n",
    "    tokens = output['sentences'][0]['tokens']\n",
    "    parse = output['sentences'][0]['parse'].split(\"\\n\")\n",
    "    return {\n",
    "        'toks':tokens, 'parse':parse\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDuffyScore(sent1,sent2):\n",
    "    tree_1=tree()\n",
    "    tree_2=tree()\n",
    "    out1=getNLPToks(sent1)\n",
    "    out2=getNLPToks(sent2)\n",
    "    generateTree(out1['parse'],tree_1)\n",
    "    generateTree(out2['parse'],tree_2)\n",
    "    flipTree(tree_1)\n",
    "    flipTree(tree_2)\n",
    "    (rscore_st, nscore_st) = CollinsDuffy(tree_1, tree_2, 0.8, 1, 1)\n",
    "    return rscore_st,nscore_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMoschittiScore(sent1,sent2):\n",
    "    tree_1=tree()\n",
    "    tree_2=tree()\n",
    "    out1=getNLPToks(sent1)\n",
    "    out2=getNLPToks(sent2)\n",
    "    generateTree(out1['parse'],tree_1)\n",
    "    generateTree(out2['parse'],tree_2)\n",
    "    flipTree(tree_1)\n",
    "    flipTree(tree_2)\n",
    "    (rscore_st, nscore_st) = MoschittiPT(tree_1, tree_2, 0.8, 1, 1)\n",
    "    return rscore_st,nscore_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.844480000000001, 0.092373053223377591)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getDuffyScore(sent1,sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.3200000000000003, 0.61944279790628143)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMoschittiScore(sent1,sent3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Testing on Project Gutenberg samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating parse trees for the new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=\"./new/1.txt\"\n",
    "testB=open(test)\n",
    "raw=testB.read()\n",
    "text = strip_headers(raw).strip()\n",
    "text=text.replace('\\n',' ')\n",
    "text=sent_tokenize(text)\n",
    "text = list(filter(lambda x: len(x)>1, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2910\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-8-fdc86d760f50>\"\u001b[0m, line \u001b[1;32m3\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    sentParse=getNLPToks(sent)\n",
      "  File \u001b[1;32m\"<ipython-input-5-51c2cfd1273a>\"\u001b[0m, line \u001b[1;32m3\u001b[0m, in \u001b[1;35mgetNLPToks\u001b[0m\n    output=ast.literal_eval(output)\n",
      "  File \u001b[1;32m\"/usr/lib64/python3.6/ast.py\"\u001b[0m, line \u001b[1;32m48\u001b[0m, in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string, mode='eval')\n",
      "\u001b[0;36m  File \u001b[0;32m\"/usr/lib64/python3.6/ast.py\"\u001b[0;36m, line \u001b[0;32m35\u001b[0;36m, in \u001b[0;35mparse\u001b[0;36m\u001b[0m\n\u001b[0;31m    return compile(source, filename, mode, PyCF_ONLY_AST)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    CoreNLP request timed out. Your document may be too long.\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "parseTrees=list()\n",
    "for sent in text:\n",
    "    sentParse=getNLPToks(sent)\n",
    "    tempTree=tree()\n",
    "    generateTree(sentParse['parse'],tempTree)\n",
    "    flipTree(tempTree)\n",
    "    parseTrees.append(tempTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parseTrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading candidates and creating parse trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential=\"./potential/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "potentialParseTrees=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.txt\n",
      "2.txt\n",
      "3.txt\n",
      "5.txt\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(potential):\n",
    "    print(file)\n",
    "    candidate=open(potential+file)\n",
    "    rawtext=candidate.read()\n",
    "    rawtext = strip_headers(rawtext).strip()\n",
    "    candidate=rawtext.replace('\\n',' ')\n",
    "    candidate=sent_tokenize(candidate)\n",
    "    pTrees=list()\n",
    "    for sent in candidate:\n",
    "        sentParse=getNLPToks(sent)\n",
    "        tempTree=tree()\n",
    "        generateTree(sentParse['parse'],tempTree)\n",
    "        flipTree(tempTree)\n",
    "        pTrees.append(tempTree)\n",
    "    potentialParseTrees[file]=pTrees\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(potentialParseTrees['5.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "4.txt\n",
      "[0.8391088911251221, 0.59119756689857583, 0.93560691999895162, 0.89504879700461026, 0.8398424710021698, 0.55269603715741278, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.21250157716599583, 0.78040641316802439, 0.73826147574669465, 0.53164795295535183, 0.5354382506076778, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.49965313904947828, 0.68218656121950705, 0.44854096759947359, 0.67917874637167908, 0.66678454638192208, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.47781997902140938, 0.062317695284975591, 0.062317695284975591, 0.75363198250110341, 0.062317695284975591, 0.062317695284975591, 0.73367215564184551, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.42472887024125272]\n",
      "2.txt\n",
      "[0.8391088911251221, 0.59119756689857583, 0.71897359373280934, 0.74160861837744574, 0.87085210532357593, 0.79549163402291911, 0.81796676806200064, 0.7328400868935403, 0.82834196153090478, 0.79001273586969634, 0.87064625777198446, 0.41814683964569777, 0.80363861211249754, 0.73626812491593374]\n",
      "3.txt\n",
      "[0.8391088911251221, 0.59119756689857583, 1.0, 0.84617968158681145, 0.062317695284975591, 0.062317695284975591, 0.57021958919975191, 0.062317695284975591, 0.062317695284975591, 0.81572609796731665, 0.70270258535102892, 0.062317695284975591, 0.062317695284975591, 0.73205847527811818, 0.55469790128917573, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.72909442545514869, 0.062317695284975591, 0.062317695284975591, 0.7196750156696875, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.35979138148057721, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.68643429375334664, 0.48773902944240993, 0.062317695284975591, 0.062317695284975591, 0.80968326354825648, 0.40555818505119789, 0.062317695284975591, 0.062317695284975591, 0.1689825771046658, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.79362113441526916, 0.41849272290994688, 0.42085492326840468, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.79762190644131103, 0.062317695284975591, 0.062317695284975591, 0.55159724446065206, 0.73747482115003549, 0.062317695284975591, 0.062317695284975591, 0.44296580239906047, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.80616191211059152, 0.65692110714634655, 0.062317695284975591, 0.062317695284975591, 0.77216440223418092, 0.062317695284975591, 0.062317695284975591, 0.86953968357771205, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.45318358675561193, 0.84289548359409827, 0.64422358438240379, 0.53084420136504207, 0.74591416824161405, 0.062317695284975591, 0.062317695284975591, 0.36905791251346953, 0.062317695284975591, 0.062317695284975591, 0.48662115004580891, 0.5943193904234122, 0.7937742268248309, 0.062317695284975591, 0.062317695284975591, 0.73954416118514654, 0.67675481366600443, 0.8004921809023432, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.3774455923433212, 0.78793393967473546, 0.062317695284975591, 0.062317695284975591, 0.68265614878628911, 0.062317695284975591, 0.062317695284975591, 0.69422741609120875, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.57824730294718685, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.5296144870133076, 0.53547892167524958, 0.062317695284975591, 0.062317695284975591, 0.81182592072186477, 0.35979138148057721, 0.20277909252559895, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.61858620768535033, 0.79630744918606577, 0.70369901782815336, 0.062317695284975591, 0.062317695284975591, 0.55440648991583086, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.6183647035906491, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.67829355802546876, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.38498902200747587, 0.062317695284975591, 0.062317695284975591, 0.52774080836834369, 0.83267937962074723, 0.062317695284975591, 0.062317695284975591, 0.7312244007500236, 0.76511606939801724, 0.062317695284975591, 0.062317695284975591, 0.73048615319551102, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.062317695284975591, 0.76423101322395537, 0.062317695284975591, 0.062317695284975591, 0.87151557611608976, 0.80229985199343468]\n",
      "5.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c15445adc027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbTree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbookTrees\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mrscore_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnscore_st\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMoschittiPT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnscore_st\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-c75b7c01dcd5>\u001b[0m in \u001b[0;36mMoschittiPT\u001b[0;34m(tree1, tree2, lam, mu, NORMALIZE_FLAG)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNORMALIZE_FLAG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mt1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ptKernel_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mt2_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ptKernel_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_score\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1_score\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mt2_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-c75b7c01dcd5>\u001b[0m in \u001b[0;36m_ptKernel_\u001b[0;34m(tree1, tree2, lam, mu)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0m_delta_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-c75b7c01dcd5>\u001b[0m in \u001b[0;36m_delta_\u001b[0;34m(tree1, tree2, node1, node2, store, lam, mu)\u001b[0m\n\u001b[1;32m    140\u001b[0m                 deltaTot += _deltaP_(tree1, tree2,\n\u001b[1;32m    141\u001b[0m                                      \u001b[0mtree1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'children'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                                      tree2[node2]['children'], store, lam, mu, p)\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mstore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdeltaTot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-c75b7c01dcd5>\u001b[0m in \u001b[0;36m_deltaP_\u001b[0;34m(tree1, tree2, seq1, seq2, store, lam, mu, p)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0mscaleFactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deltaP_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                     \u001b[0mrunningTot\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscaleFactor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrunningTot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-c75b7c01dcd5>\u001b[0m in \u001b[0;36m_deltaP_\u001b[0;34m(tree1, tree2, seq1, seq2, store, lam, mu, p)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0mscaleFactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deltaP_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                     \u001b[0mrunningTot\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscaleFactor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrunningTot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-c75b7c01dcd5>\u001b[0m in \u001b[0;36m_deltaP_\u001b[0;34m(tree1, tree2, seq1, seq2, store, lam, mu, p)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                     \u001b[0mscaleFactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m                     \u001b[0mdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deltaP_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                     \u001b[0mrunningTot\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscaleFactor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "allScores=list()\n",
    "i=0\n",
    "for tr in parseTrees:\n",
    "    print(i)\n",
    "    if i%10==0:\n",
    "        print(i)\n",
    "    sentScoreDict=dict()\n",
    "    for file in os.listdir(potential):\n",
    "        print(file)\n",
    "        bookTrees=potentialParseTrees[file]\n",
    "        df=list()\n",
    "        for bTree in bookTrees:\n",
    "            (rscore_st, nscore_st) = MoschittiPT(tr, bTree, 0.8, 1, 1)\n",
    "            df.append(nscore_st)\n",
    "        print(df)\n",
    "        sentScoreDict[file]=df\n",
    "    allScores.append(sentScoreDict)\n",
    "    print('over')\n",
    "    i=i+1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.txt\n",
      "2.txt\n",
      "3.txt\n",
      "5.txt\n"
     ]
    }
   ],
   "source": [
    "books=dict()\n",
    "for file in os.listdir(potential):\n",
    "    print(file)\n",
    "    candidate=open(potential+file)\n",
    "    rawtext=candidate.read()\n",
    "    rawtext = strip_headers(rawtext).strip()\n",
    "    candidate=rawtext.replace('\\n',' ')\n",
    "    candidate=sent_tokenize(candidate)\n",
    "    books[file]=candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1\n",
      "Original Sent Gutenberg Etexts, offically dated November 22, 1973--\n",
      "2.txt\n",
      "Score 0.721916509666\n",
      "Similar sentence: All of the original Project Gutenberg Etexts from the\n",
      "3.txt\n",
      "Score 1.0\n",
      "Similar sentence: Gutenberg Etexts, offically dated November 22, 1973--\n",
      "4.txt\n",
      "Score 1.0\n",
      "Similar sentence: Gutenberg Etexts, offically dated December 31, 1974--\n",
      "5.txt\n",
      "Score 0.763948242908\n",
      "Similar sentence: one of our earlier Project Gutenberg Etexts, and the others will be sent\n",
      "\n",
      "\n",
      "\n",
      "Sentence 2\n",
      "Original Sent and now officially re-released on November 22, 1993--\n",
      "2.txt\n",
      "Score 0.70547291554\n",
      "Similar sentence: and cause of the accusation; to be confronted with the witnesses against him;\n",
      "3.txt\n",
      "Score 1.0\n",
      "Similar sentence: and now officially re-released on November 22, 1993--\n",
      "4.txt\n",
      "Score 0.957983193277\n",
      "Similar sentence: and now officially re-released on November 19, 1993--\n",
      "5.txt\n",
      "Score 0.770909781933\n",
      "Similar sentence: and make Rules concerning Captures on Land and Water;\n",
      "\n",
      "\n",
      "\n",
      "Sentence 3\n",
      "Original Sent on the 30th anniversary of his assassination.\n",
      "2.txt\n",
      "Score 0.779930796248\n",
      "Similar sentence: without the consent of the owner, nor in time of war,\n",
      "3.txt\n",
      "Score 1.0\n",
      "Similar sentence: on the 30th anniversary of his assassination.\n",
      "4.txt\n",
      "Score 0.832050294338\n",
      "Similar sentence: November 22, 1993, on the day of the 30th anniversary\n",
      "5.txt\n",
      "Score 0.821628075001\n",
      "Similar sentence: Invasion; and on Application of the Legislature, or of the Executive\n",
      "\n",
      "\n",
      "\n",
      "Sentence 4\n",
      "Original Sent ***The Project Gutenberg Etext of Kennedy's Inaugural Address**\n",
      "2.txt\n",
      "Score 0.867212051276\n",
      "Similar sentence: All of the original Project Gutenberg Etexts from the\n",
      "3.txt\n",
      "Score 1.0\n",
      "Similar sentence: ***The Project Gutenberg Etext of Kennedy's Inaugural Address**\n",
      "4.txt\n",
      "Score 0.867212051276\n",
      "Similar sentence: All of the original Project Gutenberg Etexts from the\n",
      "5.txt\n",
      "Score 0.872398140737\n",
      "Similar sentence: Ambassadors, other public Ministers and Consuls;--to all Cases of admiralty\n",
      "\n",
      "\n",
      "\n",
      "Sentence 5\n",
      "Original Sent JFK's Inaugural Address, January 20, 1961, 12:11 EST\n",
      "2.txt\n",
      "Score 0.762017380088\n",
      "Similar sentence: All of the original Project Gutenberg Etexts from the\n",
      "3.txt\n",
      "Score 1.0\n",
      "Similar sentence: JFK's Inaugural Address, January 20, 1961, 12:11 EST\n",
      "4.txt\n",
      "Score 0.798276002095\n",
      "Similar sentence: Lincoln's Gettysburg Address, given November 19, 1863\n",
      "5.txt\n",
      "Score 0.816514867321\n",
      "Similar sentence: Ambassadors, other public Ministers and Consuls;--to all Cases of admiralty\n",
      "\n",
      "\n",
      "\n",
      "Sentence 6\n",
      "Original Sent We observe today not a victory of party but a celebration of freedom. . .\n",
      "2.txt\n",
      "Score 0.838952046382\n",
      "Similar sentence: A well-regulated militia, being necessary to the security of a free State,\n",
      "3.txt\n",
      "Score 1.0\n",
      "Similar sentence: We observe today not a victory of party but a celebration of freedom. . .\n",
      "4.txt\n",
      "Score 0.840791523675\n",
      "Similar sentence: This is a retranscription of one of the first Project\n",
      "5.txt\n",
      "Score 0.873961087658\n",
      "Similar sentence: bound to Service for a Term of Years, and excluding Indians not taxed,\n",
      "\n",
      "\n",
      "\n",
      "Sentence 7\n",
      "Original Sent symbolizing an end as well as a beginning. . .signifying renewal\n",
      "2.txt\n",
      "Score 0.731925054711\n",
      "Similar sentence: Congress shall make no law respecting an establishment of religion,\n",
      "3.txt\n",
      "Score 1.0\n",
      "Similar sentence: symbolizing an end as well as a beginning. . .signifying renewal\n",
      "4.txt\n",
      "Score 0.715329229399\n",
      "Similar sentence: We have come to dedicate a portion of that field as a final resting place\n",
      "5.txt\n",
      "Score 0.756978119245\n",
      "Similar sentence: following Oath or Affirmation:--\"I do solemnly swear (or affirm) that\n",
      "\n",
      "\n",
      "\n",
      "Sentence 8\n",
      "Original Sent as well as change for I have sworn before you and Almighty God\n",
      "2.txt\n",
      "Score 0.768716259039\n",
      "Similar sentence: in time of War or public danger; nor shall any person be subject for\n",
      "3.txt\n",
      "Score 1.0\n",
      "Similar sentence: as well as change for I have sworn before you and Almighty God\n",
      "4.txt\n",
      "Score 0.754414190853\n",
      "Similar sentence: to that cause for which they gave the last full measure of devotion. . .\n",
      "5.txt\n",
      "Score 0.789179821768\n",
      "Similar sentence: chuse by Ballot one of them for President; and if no Person have\n",
      "\n",
      "\n",
      "\n",
      "Sentence 9\n",
      "Original Sent the same solemn oath our forbears prescribed nearly a century\n",
      "2.txt\n",
      "Score 0.69675484959\n",
      "Similar sentence: All of the original Project Gutenberg Etexts from the\n",
      "3.txt\n",
      "Score 1.0\n",
      "Similar sentence: the same solemn oath our forbears prescribed nearly a century\n",
      "4.txt\n",
      "Score 0.69675484959\n",
      "Similar sentence: All of the original Project Gutenberg Etexts from the\n",
      "5.txt\n",
      "Score 0.734038681125\n",
      "Similar sentence: Trust or Profit under the United States:  but the Party convicted shall\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    print('Sentence',i)\n",
    "    print('Original Sent',text[i])\n",
    "    for book in os.listdir(potential):\n",
    "        print(book)\n",
    "        maxIndex=allScores[i][book].index(max(allScores[i][book]))\n",
    "        print('Score',allScores[i][book][maxIndex])\n",
    "        print('Similar sentence:',books[book][maxIndex])\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allScores[600]['2.txt'].index(max(allScores[600]['2.txt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "639"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allScores[0]['5.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python personal",
   "language": "python",
   "name": "py3env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
