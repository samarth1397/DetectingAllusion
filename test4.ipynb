{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from nltk.corpus import wordnet as wn\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import re\n",
    "import bisect\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "import os\n",
    "from gutenberg.cleanup import strip_headers\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "public='/home/users2/mehrotsh/scripts/packages/stanford-corenlp-full-2018-02-27/'\n",
    "personal='/home/samarth/stanford-corenlp-full-2018-02-27/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP(personal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tree(): \n",
    "    return defaultdict(tree)\n",
    "\n",
    "\n",
    "def _leadingSpaces_(target):\n",
    "    return len(target) - len(target.lstrip())\n",
    "\n",
    "def _findParent_(curIndent, parid, treeRef):\n",
    "    tmpid = parid\n",
    "    while (curIndent <= treeRef[tmpid]['indent']):\n",
    "        tmpid = treeRef[tmpid]['parid']\n",
    "    return tmpid\n",
    "\n",
    "\n",
    "def generateTree(rawTokens, treeRef):\n",
    "\n",
    "    # (token\n",
    "    REGEX_OPEN = r\"^\\s*\\(([a-zA-Z0-9_']*)\\s*$\"\n",
    "    # (token (tok1 tok2) (tok3 tok4) .... (tokx toky))\n",
    "    REGEX_COMP = r\"^\\s*\\(([a-zA-Z0-9_']+)\\s*((?:[(]([a-zA-Z0-9_;.,?'!]+)\\s*([a-zA-Z0-9_;\\.,?!']+)[)]\\s*)+)\"    \n",
    "    # (, ,) as stand-alone. Used for match() not search()\n",
    "    REGEX_PUNC = r\"^\\s*\\([,!?.'\\\"]\\s*[,!?.'\\\"]\\)\"\n",
    "    # (tok1 tok2) as stand-alone\n",
    "    REGEX_SOLO_PAIR = r\"^\\s*\\(([a-zA-Z0-9_']+)\\s*([a-zA-Z0-9_']+)\\)\"\n",
    "    # (tok1 tok2) used in search()\n",
    "    REGEX_ISOL_IN_COMP = r\"\\(([a-zA-Z0-9_;.,?!']+)\\s*([a-zA-Z0-9_;.,?!']+)\\)\"\n",
    "    # (punc punc) used in search()\n",
    "    REGEX_PUNC_SOLO = r\"\\([,!?.'\\\"]\\s*[,!?.'\\\"]\\)\"\n",
    "  \n",
    "    # manually insert Root token \n",
    "    treeRef[len(treeRef)] = {'curid':0, \n",
    "                             'parid':-1, \n",
    "                             'posOrTok':'ROOT', \n",
    "                             'indent':0,\n",
    "                            'children':[],\n",
    "                            'childrenTok':[]}\n",
    "    ID_CTR = 1\n",
    "    \n",
    "    for tok in rawTokens[1:]:\n",
    "        \n",
    "        curIndent = _leadingSpaces_(tok) # the current indent level\n",
    "        parid = _findParent_(curIndent, ID_CTR-1, treeRef) # determine parid\n",
    "        \n",
    "        # CHECK FOR COMPOSITE TOKENS\n",
    "        checkChild = re.match(REGEX_COMP, tok)\n",
    "        if (checkChild):\n",
    "            treeRef[ID_CTR] = {'curid':ID_CTR, \n",
    "                               'parid':parid, \n",
    "                               'posOrTok':checkChild.group(1), \n",
    "                               'indent':curIndent,\n",
    "                              'children':[],\n",
    "                              'childrenTok':[]}\n",
    "            upCTR = ID_CTR\n",
    "            ID_CTR += 1\n",
    "            \n",
    "            subCheck = re.sub(REGEX_PUNC_SOLO,'',checkChild.group(2))\n",
    "            subs = re.findall(REGEX_ISOL_IN_COMP, subCheck) \n",
    "            for ch in subs:\n",
    "                treeRef[ID_CTR] = {'curid':ID_CTR, \n",
    "                                   'parid':upCTR, \n",
    "                                   'posOrTok':ch[0], \n",
    "                                   'indent':curIndent+2,\n",
    "                                  'children':[],\n",
    "                                  'childrenTok':[]}\n",
    "                ID_CTR += 1\n",
    "                treeRef[ID_CTR] = {'curid':ID_CTR, \n",
    "                                   'parid':ID_CTR-1, \n",
    "                                   'posOrTok':ch[1], \n",
    "                                   'indent':curIndent+2,\n",
    "                                  'children':[],\n",
    "                                  'childrenTok':[]}\n",
    "                ID_CTR += 1\n",
    "            continue\n",
    "           \n",
    "\n",
    "            \n",
    "        checkSingle = re.match(REGEX_SOLO_PAIR, tok)\n",
    "        if (checkSingle):\n",
    "            treeRef[ID_CTR] = {'curid':ID_CTR, \n",
    "                               'parid':parid, \n",
    "                               'posOrTok':checkSingle.group(1), \n",
    "                               'indent':curIndent+2,\n",
    "                              'children':[],\n",
    "                              'childrenTok':[]}\n",
    "            ID_CTR += 1\n",
    "            treeRef[ID_CTR] = {'curid':ID_CTR, \n",
    "                               'parid':ID_CTR-1, \n",
    "                               'posOrTok':checkSingle.group(2), \n",
    "                               'indent':curIndent+2,\n",
    "                              'children':[],\n",
    "                              'childrenTok':[]}\n",
    "            ID_CTR += 1\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        checkPunc = re.match(REGEX_PUNC, tok)\n",
    "        if (checkPunc): # ignore punctuation\n",
    "            continue\n",
    "\n",
    "        checkMatch = re.match(REGEX_OPEN, tok)\n",
    "        if (checkMatch):\n",
    "            treeRef[ID_CTR] = {'curid':ID_CTR, \n",
    "                               'parid':parid, \n",
    "                               'posOrTok':checkMatch.group(1), \n",
    "                               'indent':curIndent,\n",
    "                              'children':[],\n",
    "                              'childrenTok':[]}\n",
    "            ID_CTR += 1\n",
    "            continue\n",
    "\n",
    "    return\n",
    "            \n",
    "\n",
    "def flipTree(treeRef):\n",
    "    # Pass 1 fill in children\n",
    "    for k,v in treeRef.items():\n",
    "        if (k > 0):\n",
    "            bisect.insort(treeRef[v['parid']]['children'], k)\n",
    "    # Pass 2 map children to tokens\n",
    "    for k,v in treeRef.items():\n",
    "        if (k > 0):\n",
    "            treeRef[k]['childrenTok'] = [treeRef[ch]['posOrTok'] for ch in treeRef[k]['children']]\n",
    "    treeRef[0]['childrenTok'] = treeRef[1]['posOrTok']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _isLeaf_(tree, parentNode):\n",
    "    return (len(tree[parentNode]['children']) == 0)\n",
    "\n",
    "def _isPreterminal_(tree, parentNode):\n",
    "    for idx in tree[parentNode]['children']:\n",
    "        if not _isLeaf_(tree, idx):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "'''\n",
    "Implementation of the Colins-Duffy or Subset-Tree (SST) Kernel\n",
    "'''\n",
    "\n",
    "def _cdHelper_(tree1, tree2, node1, node2, store, lam, SST_ON):\n",
    "    # No duplicate computations\n",
    "    if store[node1, node2] >= 0:\n",
    "        return\n",
    "\n",
    "    # Leaves yield similarity score by definition\n",
    "    if (_isLeaf_(tree1, node1) or _isLeaf_(tree2, node2)):\n",
    "        store[node1, node2] = 0\n",
    "        return\n",
    "\n",
    "    # same parent node\n",
    "    if tree1[node1]['posOrTok'] == tree2[node2]['posOrTok']:\n",
    "        # same children tokens\n",
    "        if tree1[node1]['childrenTok'] == tree2[node2]['childrenTok']:\n",
    "            # Check if both nodes are pre-terminal\n",
    "            if _isPreterminal_(tree1, node1) and _isPreterminal_(tree2, node2):\n",
    "                store[node1, node2] = lam\n",
    "                return\n",
    "            # Not pre-terminal. Recurse among the children of both token trees.\n",
    "            else:\n",
    "                nChildren = len(tree1[node1]['children'])\n",
    "\n",
    "                runningTotal = None\n",
    "                for idx in range(nChildren):\n",
    "                     # index ->  node_id\n",
    "                    tmp_n1 = tree1[node1]['children'][idx]\n",
    "                    tmp_n2 = tree2[node2]['children'][idx]\n",
    "                    # Recursively run helper\n",
    "                    _cdHelper_(tree1, tree2, tmp_n1, tmp_n2, store, lam, SST_ON)\n",
    "                    # Set the initial value for the layer. Else multiplicative product.\n",
    "                    if (runningTotal == None):\n",
    "                        runningTotal = SST_ON + store[tmp_n1, tmp_n2]\n",
    "                    else:\n",
    "                        runningTotal *= (SST_ON + store[tmp_n1, tmp_n2])\n",
    "\n",
    "                store[node1, node2] = lam * runningTotal\n",
    "                return\n",
    "        else:\n",
    "            store[node1, node2] = 0\n",
    "    else: # parent nodes are different\n",
    "        store[node1, node2] = 0\n",
    "        return\n",
    "\n",
    "\n",
    "def _cdKernel_(tree1, tree2, lam, SST_ON):\n",
    "    # Fill the initial state of the store\n",
    "    store = np.empty((len(tree1), len(tree2)))\n",
    "    store.fill(-1)\n",
    "    # O(N^2) to compute the tree dot product\n",
    "    for i in range(len(tree1)):\n",
    "        for j in range(len(tree2)):\n",
    "            _cdHelper_(tree1, tree2, i, j, store, lam, SST_ON)\n",
    "\n",
    "    return store.sum()\n",
    "\n",
    "'''\n",
    "Returns a tuple w/ format: (raw, normalized)\n",
    "If NORMALIZE_FLAG set to False, tuple[1] = -1\n",
    "'''\n",
    "def CollinsDuffy(tree1, tree2, lam, NORMALIZE_FLAG, SST_ON):\n",
    "    raw_score = _cdKernel_(tree1, tree2, lam, SST_ON)\n",
    "    if (NORMALIZE_FLAG):\n",
    "        t1_score = _cdKernel_(tree1, tree1, lam, SST_ON)\n",
    "        t2_score = _cdKernel_(tree2, tree2, lam, SST_ON)\n",
    "        return (raw_score,(raw_score / math.sqrt(t1_score * t2_score)))\n",
    "    else:\n",
    "        return (raw_score,-1)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Implementation of the Partial Tree (PT) Kernel from:\n",
    "\"Efficient Convolution Kernels for Dependency and Constituent Syntactic Trees\"\n",
    "by Alessandro Moschitti\n",
    "'''\n",
    "\n",
    "'''\n",
    "The delta function is stolen from the Collins-Duffy kernel\n",
    "'''\n",
    "\n",
    "def _deltaP_(tree1, tree2, seq1, seq2, store, lam, mu, p):\n",
    "\n",
    "#     # Enumerate subsequences of length p+1 for each child set\n",
    "    if p == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        # generate delta(a,b)\n",
    "        _delta_(tree1, tree2, seq1[-1], seq2[-1], store, lam, mu)\n",
    "        if store[seq1[-1], seq2[-1]] == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            runningTot = 0\n",
    "            for i in range(p-1, len(seq1)-1):\n",
    "                for r in range(p-1, len(seq2)-1):\n",
    "                    scaleFactor = pow(lam, len(seq1[:-1])-i+len(seq2[:-1])-r)\n",
    "                    dp = _deltaP_(tree1, tree2, seq1[:i], seq2[:r], store, lam, mu, p-1)\n",
    "                    runningTot += (scaleFactor * dp)\n",
    "            return runningTot\n",
    "\n",
    "def _delta_(tree1, tree2, node1, node2, store, lam, mu):\n",
    "\n",
    "    # No duplicate computations\n",
    "    if store[node1, node2] >= 0:\n",
    "        return\n",
    "\n",
    "    # Leaves yield similarity score by definition\n",
    "    if (_isLeaf_(tree1, node1) or _isLeaf_(tree2, node2)):\n",
    "        store[node1, node2] = 0\n",
    "        return\n",
    "\n",
    "    # same parent node\n",
    "    if tree1[node1]['posOrTok'] == tree2[node2]['posOrTok']:\n",
    "\n",
    "        if _isPreterminal_(tree1, node1) and _isPreterminal_(tree2, node2):\n",
    "            if tree1[node1]['childrenTok'] == tree2[node2]['childrenTok']:\n",
    "                store[node1, node2] = lam\n",
    "            else:\n",
    "                store[node1, node2] = 0\n",
    "            return\n",
    "\n",
    "        else:\n",
    "            # establishes p_max\n",
    "            childmin = min(len(tree1[node1]['children']), len(tree2[node2]['children']))\n",
    "            deltaTot = 0\n",
    "            for p in range(1,childmin+1):\n",
    "                # compute delta_p\n",
    "                deltaTot += _deltaP_(tree1, tree2,\n",
    "                                     tree1[node1]['children'],\n",
    "                                     tree2[node2]['children'], store, lam, mu, p)\n",
    "\n",
    "            store[node1, node2] = mu * (pow(lam,2) + deltaTot)\n",
    "            return\n",
    "\n",
    "    else:\n",
    "        # parent nodes are different\n",
    "        store[node1, node2] = 0\n",
    "        return\n",
    "\n",
    "def _ptKernel_(tree1, tree2, lam, mu):\n",
    "    # Fill the initial state of the store\n",
    "    store = np.empty((len(tree1), len(tree2)))\n",
    "    store.fill(-1)\n",
    "\n",
    "    # O(N^2) to compute the tree dot product\n",
    "    for i in range(len(tree1)):\n",
    "        for j in range(len(tree2)):\n",
    "            _delta_(tree1, tree2, i, j, store, lam, mu)\n",
    "\n",
    "    return store.sum()\n",
    "\n",
    "'''\n",
    "Returns a tuple w/ format: (raw, normalized)\n",
    "If NORMALIZE_FLAG set to False, tuple[1] = -1\n",
    "'''\n",
    "def MoschittiPT(tree1, tree2, lam, mu, NORMALIZE_FLAG):\n",
    "    raw_score = _ptKernel_(tree1, tree2, lam, mu)\n",
    "    if (NORMALIZE_FLAG):\n",
    "        t1_score = _ptKernel_(tree1, tree1, lam, mu)\n",
    "        t2_score = _ptKernel_(tree2, tree2, lam, mu)\n",
    "        return (raw_score,(raw_score / math.sqrt(t1_score * t2_score)))\n",
    "    else:\n",
    "        return (raw_score,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on example sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent1='the quick brown fox jumps over the lazy dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent2='the slow fox jumped over the quick dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent5='the fast dark cat jumped over the slow mouse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent3='usually, a fox jumps over a dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent4='cats sleep throughout the day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNLPToks(rawSentence):\n",
    "    output = nlp.annotate(rawSentence, properties={'annotators': 'tokenize,ssplit,pos,parse','outputFormat': 'json'})\n",
    "    output=ast.literal_eval(output)\n",
    "    tokens = output['sentences'][0]['tokens']\n",
    "    parse = output['sentences'][0]['parse'].split(\"\\n\")\n",
    "    return {\n",
    "        'toks':tokens, 'parse':parse\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDuffyScore(sent1,sent2):\n",
    "    tree_1=tree()\n",
    "    tree_2=tree()\n",
    "    out1=getNLPToks(sent1)\n",
    "    out2=getNLPToks(sent2)\n",
    "    generateTree(out1['parse'],tree_1)\n",
    "    generateTree(out2['parse'],tree_2)\n",
    "    flipTree(tree_1)\n",
    "    flipTree(tree_2)\n",
    "    (rscore_st, nscore_st) = CollinsDuffy(tree_1, tree_2, 0.8, 1, 1)\n",
    "    return rscore_st,nscore_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMoschittiScore(sent1,sent2):\n",
    "    tree_1=tree()\n",
    "    tree_2=tree()\n",
    "    out1=getNLPToks(sent1)\n",
    "    out2=getNLPToks(sent2)\n",
    "    generateTree(out1['parse'],tree_1)\n",
    "    generateTree(out2['parse'],tree_2)\n",
    "    flipTree(tree_1)\n",
    "    flipTree(tree_2)\n",
    "    (rscore_st, nscore_st) = MoschittiPT(tree_1, tree_2, 0.8, 1, 1)\n",
    "    return rscore_st,nscore_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "getDuffyScore(sent1,sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "getMoschittiScore(sent1,sent3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Testing on Project Gutenberg samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating parse trees for the new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=\"./new/1.txt\"\n",
    "testB=open(test)\n",
    "raw=testB.read()\n",
    "text = strip_headers(raw).strip()\n",
    "text=text.replace('\\n',' ')\n",
    "text=sent_tokenize(text)\n",
    "text = list(filter(lambda x: len(x)>1, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parseTrees=list()\n",
    "for sent in text:\n",
    "    sentParse=getNLPToks(sent)\n",
    "    tempTree=tree()\n",
    "    generateTree(sentParse['parse'],tempTree)\n",
    "    flipTree(tempTree)\n",
    "    parseTrees.append(tempTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parseTrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading candidates and creating parse trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "potential=\"./potential/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "potentialParseTrees=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.txt\n",
      "3.txt\n",
      "4.txt\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(potential):\n",
    "    print(file)\n",
    "    candidate=open(potential+file)\n",
    "    rawtext=candidate.read()\n",
    "    rawtext = strip_headers(rawtext).strip()\n",
    "    candidate=rawtext.replace('\\n',' ')\n",
    "    candidate=sent_tokenize(candidate)\n",
    "    candidate = list(filter(lambda x: len(x)>1, candidate))\n",
    "    pTrees=list()\n",
    "    for sent in candidate:\n",
    "        sentParse=getNLPToks(sent)\n",
    "        tempTree=tree()\n",
    "        generateTree(sentParse['parse'],tempTree)\n",
    "        flipTree(tempTree)\n",
    "        pTrees.append(tempTree)\n",
    "    potentialParseTrees[file]=pTrees\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(potentialParseTrees['4.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-bc60b887548c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbTree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbookTrees\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mrscore_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnscore_st\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMoschittiPT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnscore_st\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#         print(df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-acb7425e4a4c>\u001b[0m in \u001b[0;36mMoschittiPT\u001b[0;34m(tree1, tree2, lam, mu, NORMALIZE_FLAG)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0mraw_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ptKernel_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNORMALIZE_FLAG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mt1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ptKernel_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mt2_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ptKernel_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_score\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1_score\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mt2_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-acb7425e4a4c>\u001b[0m in \u001b[0;36m_ptKernel_\u001b[0;34m(tree1, tree2, lam, mu)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0m_delta_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-acb7425e4a4c>\u001b[0m in \u001b[0;36m_delta_\u001b[0;34m(tree1, tree2, node1, node2, store, lam, mu)\u001b[0m\n\u001b[1;32m    140\u001b[0m                 deltaTot += _deltaP_(tree1, tree2,\n\u001b[1;32m    141\u001b[0m                                      \u001b[0mtree1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'children'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                                      tree2[node2]['children'], store, lam, mu, p)\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mstore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdeltaTot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-acb7425e4a4c>\u001b[0m in \u001b[0;36m_deltaP_\u001b[0;34m(tree1, tree2, seq1, seq2, store, lam, mu, p)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0mscaleFactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deltaP_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                     \u001b[0mrunningTot\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscaleFactor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrunningTot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-acb7425e4a4c>\u001b[0m in \u001b[0;36m_deltaP_\u001b[0;34m(tree1, tree2, seq1, seq2, store, lam, mu, p)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0mscaleFactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deltaP_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                     \u001b[0mrunningTot\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscaleFactor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrunningTot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-acb7425e4a4c>\u001b[0m in \u001b[0;36m_deltaP_\u001b[0;34m(tree1, tree2, seq1, seq2, store, lam, mu, p)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                     \u001b[0mscaleFactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m                     \u001b[0mdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deltaP_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                     \u001b[0mrunningTot\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscaleFactor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "allScores=list()\n",
    "i=0\n",
    "for tr in parseTrees:\n",
    "#     print(i)\n",
    "    if i%10==0:\n",
    "        print(i)\n",
    "    sentScoreDict=dict()\n",
    "    for file in os.listdir(potential):\n",
    "#         print(file)\n",
    "        bookTrees=potentialParseTrees[file]\n",
    "        df=list()\n",
    "        for bTree in bookTrees:\n",
    "            (rscore_st, nscore_st) = MoschittiPT(tr, bTree, 0.8, 1, 1)\n",
    "            df.append(nscore_st)\n",
    "#         print(df)\n",
    "        sentScoreDict[file]=df\n",
    "    allScores.append(sentScoreDict)\n",
    "#     print('over')\n",
    "    i=i+1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Congress shall have Power to lay and collect Taxes, Duties, Imposts and Excises, to pay the Debts and provide for the common Defence and general Welfare of the United States; but all Duties, Imposts and Excises shall be uniform throughout the United States;  To borrow Money on the credit of the United States;  To regulate Commerce with foreign Nations, and among the several States, and with the Indian Tribes;  To establish an uniform Rule of Naturalization, and uniform Laws on the subject of Bankruptcies throughout the United States;  To coin Money, regulate the Value thereof, and of foreign Coin, and fix the Standard of Weights and Measures;  To provide for the Punishment of counterfeiting the Securities and current Coin of the United States;  To establish Post Offices and Post Roads;  To promote the Progress of Science and useful Arts, by securing for limited Times to Authors and Inventors the exclusive Right to their respective Writings and Discoveries;  To constitute Tribunals inferior to the supreme Court;  To define and punish Piracies and Felonies committed on the high Seas, and Offenses against the Law of Nations;  To declare War, grant Letters of Marque and Reprisal, and make Rules concerning Captures on Land and Water;  To raise and support Armies, but no Appropriation of Money to that Use shall be for a longer term than two Years;  To provide and maintain a Navy;  To make Rules for the Government and Regulation of the land and naval Forces;  To provide for calling forth the Militia to execute the Laws of the Union, suppress Insurrections and repel Invasions;  To provide for organizing, arming, and disciplining, the Militia, and for governing such Part of them as may be employed in the Service of the United States, reserving to the States respectively, the Appointment of the Officers, and the Authority of training the militia according to the discipline prescribed by Congress;  To exercise exclusive Legislation in all Cases whatsoever, over such District (not exceeding ten Miles square) as may, by Cession of particular States, and the Acceptance of Congress, become the Seat of the Government of the United States, and to exercise like Authority over all Places purchased by the Consent of the Legislature of the State in which the Same shall be, for the Erection of Forts, Magazines, Arsenals, Dockyards, and other needful Buildings;--And  To make all Laws which shall be necessary and proper for carrying into Execution the foregoing Powers, and all other Powers vested by this Constitution in the Government of the United States, or in any Department or Officer thereof.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[174]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allScores=allScores[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.txt\n",
      "3.txt\n",
      "4.txt\n"
     ]
    }
   ],
   "source": [
    "books=dict()\n",
    "for file in os.listdir(potential):\n",
    "    print(file)\n",
    "    candidate=open(potential+file)\n",
    "    rawtext=candidate.read()\n",
    "    rawtext = strip_headers(rawtext).strip()\n",
    "    candidate=rawtext.replace('\\n',' ')\n",
    "    candidate=sent_tokenize(candidate)\n",
    "    candidate = list(filter(lambda x: len(x)>1, candidate))\n",
    "    books[file]=candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(60,70):\n",
    "    print('Sentence',i)\n",
    "    print('Original Sent',text[i])\n",
    "    for book in os.listdir(potential):\n",
    "        print(book)\n",
    "        maxIndex=allScores[i][book].index(max(allScores[i][book]))\n",
    "        print('Score',allScores[i][book][maxIndex])\n",
    "        print('Similar sentence:',books[book][maxIndex])\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allScores[600]['2.txt'].index(max(allScores[600]['2.txt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(allScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(allScores[0]['5.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoreTuples=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(allScores)):\n",
    "    scoreTuple=(0,0,0,0)\n",
    "    for fl in os.listdir(potential):\n",
    "        scores=allScores[i][fl]\n",
    "        for j in range(len(scores)):\n",
    "            scoreTuples.append((i,fl,j,scores[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25085"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scoreTuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoreTuples.sort(key=lambda tup: tup[3],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '3.txt', 2, 1.0), (1, '3.txt', 3, 1.0), (2, '3.txt', 4, 1.0), (3, '3.txt', 5, 1.0), (3, '3.txt', 8, 1.0), (3, '3.txt', 11, 1.0), (3, '3.txt', 14, 1.0), (3, '3.txt', 15, 1.0), (3, '3.txt', 17, 1.0), (3, '3.txt', 20, 1.0), (3, '3.txt', 23, 1.0), (3, '3.txt', 25, 1.0), (3, '3.txt', 26, 1.0), (3, '3.txt', 30, 1.0), (3, '3.txt', 31, 1.0), (3, '3.txt', 32, 1.0), (3, '3.txt', 34, 1.0), (3, '3.txt', 38, 1.0), (3, '3.txt', 39, 1.0), (3, '3.txt', 42, 1.0), (3, '3.txt', 45, 1.0), (3, '3.txt', 46, 1.0), (3, '3.txt', 52, 1.0), (3, '3.txt', 54, 1.0), (3, '3.txt', 58, 1.0), (3, '3.txt', 62, 1.0), (3, '3.txt', 67, 1.0), (3, '3.txt', 69, 1.0), (3, '3.txt', 75, 1.0), (3, '3.txt', 76, 1.0), (3, '3.txt', 81, 1.0), (3, '3.txt', 83, 1.0), (3, '3.txt', 84, 1.0), (3, '3.txt', 85, 1.0), (3, '3.txt', 86, 1.0), (3, '3.txt', 87, 1.0), (3, '3.txt', 88, 1.0), (3, '3.txt', 90, 1.0), (3, '3.txt', 92, 1.0), (3, '3.txt', 95, 1.0), (3, '3.txt', 98, 1.0), (3, '3.txt', 100, 1.0), (3, '3.txt', 101, 1.0), (3, '3.txt', 103, 1.0), (3, '4.txt', 6, 1.0), (3, '4.txt', 12, 1.0), (3, '4.txt', 18, 1.0), (3, '4.txt', 22, 1.0), (3, '4.txt', 23, 1.0), (4, '3.txt', 6, 1.0), (5, '3.txt', 7, 1.0), (6, '3.txt', 5, 1.0), (6, '3.txt', 8, 1.0), (6, '3.txt', 11, 1.0), (6, '3.txt', 14, 1.0), (6, '3.txt', 15, 1.0), (6, '3.txt', 17, 1.0), (6, '3.txt', 20, 1.0), (6, '3.txt', 23, 1.0), (6, '3.txt', 25, 1.0), (6, '3.txt', 26, 1.0), (6, '3.txt', 30, 1.0), (6, '3.txt', 31, 1.0), (6, '3.txt', 32, 1.0), (6, '3.txt', 34, 1.0), (6, '3.txt', 38, 1.0), (6, '3.txt', 39, 1.0), (6, '3.txt', 42, 1.0), (6, '3.txt', 45, 1.0), (6, '3.txt', 46, 1.0), (6, '3.txt', 52, 1.0), (6, '3.txt', 54, 1.0), (6, '3.txt', 58, 1.0), (6, '3.txt', 62, 1.0), (6, '3.txt', 67, 1.0), (6, '3.txt', 69, 1.0), (6, '3.txt', 75, 1.0), (6, '3.txt', 76, 1.0), (6, '3.txt', 81, 1.0), (6, '3.txt', 83, 1.0), (6, '3.txt', 84, 1.0), (6, '3.txt', 85, 1.0), (6, '3.txt', 86, 1.0), (6, '3.txt', 87, 1.0), (6, '3.txt', 88, 1.0), (6, '3.txt', 90, 1.0), (6, '3.txt', 92, 1.0), (6, '3.txt', 95, 1.0), (6, '3.txt', 98, 1.0), (6, '3.txt', 100, 1.0), (6, '3.txt', 101, 1.0), (6, '3.txt', 103, 1.0), (6, '4.txt', 6, 1.0), (6, '4.txt', 12, 1.0), (6, '4.txt', 18, 1.0), (6, '4.txt', 22, 1.0), (6, '4.txt', 23, 1.0), (7, '3.txt', 9, 1.0), (8, '3.txt', 10, 1.0), (9, '3.txt', 5, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "print(scoreTuples[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
